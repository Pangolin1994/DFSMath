{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "# To prevent warnings by XGBoost estimator \n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('test/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['day_id'] = pd.to_datetime(df['day_id'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Columns to delete first:')\n",
    "to_drop_singles = [c for c in df.columns\n",
    "                   if df[c].nunique() == 1]\n",
    "df.drop(columns=to_drop_singles, inplace=True)\n",
    "\n",
    "to_drop_singles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# How many samples don't have computed fp0 ?\n",
    "null_fp_mask = df['fp0'].isnull()\n",
    "print('Samples without fp0: %d' % len(df[null_fp_mask]))\n",
    "\n",
    "# Select samples with present fp0 label\n",
    "df = df[~null_fp_mask]\n",
    "df = df.set_index(pd.Index(range(len(df))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(df['fp0'], bins=20, fit=stats.norm)\n",
    "plt.figure()\n",
    "proba_plot = stats.probplot(df['fp0'], plot=plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Explicit category setting to prevent warnings\n",
    "encoder = OneHotEncoder(categories='auto')\n",
    "is_home = np.reshape(df['is_home'].values, (-1, 1))\n",
    "is_home_encoded = encoder.fit_transform(is_home).toarray()\n",
    "df[['home', 'visitor']] = pd.DataFrame(is_home_encoded, index=df.index)\n",
    "\n",
    "df.drop(columns='is_home', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Count of days must be positive numbers!\n",
    "neg_days_mask = df['p_days_since_last_game'] < 0\n",
    "print(f'Count of days invalid values: {len(df[neg_days_mask])}')\n",
    "df.loc[neg_days_mask, 'p_days_since_last_game'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "year, month, day = lambda x: x.year, lambda x: x.month, lambda x: x.day\n",
    "datetime_extraction = {'year': year, 'month': month, 'day': day}\n",
    "\n",
    "for col in datetime_extraction.keys():\n",
    "    df[col] = df['day_id'].map(datetime_extraction[col])\n",
    "\n",
    "df.drop(columns='day_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check of presence player_id for each observation\n",
    "null_ids = df[df['player_id'].isnull()]\n",
    "print('Count of null player_id\\'s: {}'.format(len(null_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Players count\n",
    "unique_ids = df['player_id'].unique()\n",
    "print('Players count in frame: {}'.format(len(unique_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def columns_by_postfix(columns, postfix):\n",
    "    result = [column for column in columns\n",
    "              if postfix in column]\n",
    "    result.sort()\n",
    "    return result\n",
    "\n",
    "def league_and_non_league_columns(columns, suffix):\n",
    "    suf_columns = columns_by_postfix(columns, suffix)\n",
    "    leagues = columns_by_postfix(suf_columns, 'league')\n",
    "    non_leagues = [column for column in suf_columns\n",
    "                   if column not in leagues]\n",
    "    return non_leagues, leagues\n",
    "\n",
    "\n",
    "cols = df.columns\n",
    "\n",
    "single_cols, league_single_cols = league_and_non_league_columns(cols, 'single')\n",
    "double_cols, league_double_cols = league_and_non_league_columns(cols, 'double')\n",
    "triple_cols, league_triple_cols = league_and_non_league_columns(cols, 'triple')\n",
    "er_cols, league_er_cols = league_and_non_league_columns(cols, 'earnedruns')\n",
    "rbi_cols, league_rbi_cols = league_and_non_league_columns(cols, 'rbi')\n",
    "ab_cols, league_ab_cols = league_and_non_league_columns(cols, 'atbat')\n",
    "ha_cols, league_ha_cols = league_and_non_league_columns(cols, 'hitsagainst')\n",
    "hr_cols, league_hr_cols = league_and_non_league_columns(cols, 'hrallowed')\n",
    "iw_cols, league_iw_cols = league_and_non_league_columns(cols, 'intwalk')\n",
    "sb_cols, league_sb_cols = league_and_non_league_columns(cols, 'stolen')\n",
    "ss_cols, league_ss_cols = league_and_non_league_columns(cols, 'swinging')\n",
    "so_cols, league_so_cols = league_and_non_league_columns(cols, 'strikeouts')\n",
    "fp0_cols, league_fp0_cols = league_and_non_league_columns(cols, 'fp0_sma')\n",
    "fp0var_cols, league_fp0var_cols =\\\n",
    "    league_and_non_league_columns(cols, 'fp0_var')\n",
    "walk_cols, league_walk_cols = league_and_non_league_columns(cols, 'walk')\n",
    "walk_cols = [col for col in walk_cols if 'int' not in col]\n",
    "league_walk_cols = [col for col in league_walk_cols if 'int' not in col]\n",
    "win_cols, league_win_cols = league_and_non_league_columns(cols, 'win_')\n",
    "nh_cols, league_nh_cols = league_and_non_league_columns(cols, 'nohitter')\n",
    "no_cols, league_no_cols = league_and_non_league_columns(cols, 'numouts')\n",
    "np_cols, league_np_cols = league_and_non_league_columns(cols, 'numpitches')\n",
    "cg_cols, league_cg_cols = league_and_non_league_columns(cols, 'completegame_')\n",
    "cgs_cols, league_cgs_cols =\\\n",
    "    league_and_non_league_columns(cols, 'completegamesho_')\n",
    "qu_cols, league_qu_cols = league_and_non_league_columns(cols, 'quality')\n",
    "gc_cols, league_gc_cols = league_and_non_league_columns(cols, 'gamescount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes = ['atbat', 'single', 'triple', 'double', 'rbi',\n",
    "            'earnedruns', 'hitsagainst', 'hr', 'intwalk', 'stolenbases',\n",
    "            'swinging', 'strikeouts', 'walk', 'win', 'nohitter',\n",
    "            'completegamesho', 'completegame', 'numpitches', 'numouts',\n",
    "            'quality', 'fp0var', 'gamecount']\n",
    "\n",
    "non_league_columns = [ab_cols, single_cols, triple_cols,\n",
    "                      double_cols, rbi_cols, er_cols, ha_cols, hr_cols,\n",
    "                      iw_cols, sb_cols, ss_cols, so_cols, walk_cols,\n",
    "                      win_cols, nh_cols, cgs_cols, cg_cols, np_cols,\n",
    "                      no_cols, qu_cols, fp0var_cols, gc_cols[1:-1]]\n",
    "\n",
    "league_columns = [league_ab_cols, league_single_cols,\n",
    "                  league_triple_cols, league_double_cols, league_rbi_cols,\n",
    "                  league_er_cols, league_ha_cols, league_hr_cols,\n",
    "                  league_iw_cols, league_sb_cols, league_ss_cols,\n",
    "                  league_so_cols, league_walk_cols, league_win_cols,\n",
    "                  league_nh_cols, league_cgs_cols, league_cg_cols,\n",
    "                  league_np_cols, league_no_cols, league_qu_cols,\n",
    "                  league_fp0var_cols, league_gc_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "indices = [0, 3, 5, 6, 7, 8, 11, 12, 13, 15, 16, 20]\n",
    "\n",
    "#prefixes = list(itemgetter(*indices)(prefixes))\n",
    "#non_league_columns = list(itemgetter(*indices)(non_league_columns))\n",
    "#league_columns = list(itemgetter(*indices)(league_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_limit_index = -5\n",
    "\n",
    "# Feature engineering (part 1)\n",
    "# Compute new features as average between similar features\n",
    "# Ex.: new_feature = sum(old_features) / old_features_count\n",
    "\n",
    "for cols, prefix in zip(non_league_columns[:pp_limit_index],\n",
    "                        prefixes[:pp_limit_index]):\n",
    "    pp_cols = columns_by_postfix(cols, 'pp')\n",
    "    pg_cols = columns_by_postfix(cols, 'pg')\n",
    "    df[prefix+'_sma_pp_avg'] = df[pp_cols].sum(axis=1) / len(pp_cols)\n",
    "    df[prefix+'_sma_pg_avg'] = df[pg_cols].sum(axis=1) / len(pg_cols)\n",
    "    \n",
    "for cols, prefix in zip(non_league_columns[pp_limit_index:],\n",
    "                        prefixes[pp_limit_index:]):\n",
    "    pg_cols = columns_by_postfix(cols, 'pg')\n",
    "    df[prefix+'_sma_pg_avg'] = df[pg_cols].sum(axis=1) / len(pg_cols)\n",
    "    \n",
    "for cols in non_league_columns:\n",
    "    df.drop(columns=cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cols, prefix in zip(league_columns[:pp_limit_index],\n",
    "                        prefixes[:pp_limit_index]):\n",
    "    pp_cols = columns_by_postfix(cols, 'pp')\n",
    "    pg_cols = columns_by_postfix(cols, 'pg')\n",
    "    df['l_'+prefix+'_sma_pp_avg'] = df[pp_cols].sum(axis=1) / len(pp_cols)\n",
    "    df['l_'+prefix+'_sma_pg_avg'] = df[pg_cols].sum(axis=1) / len(pg_cols)\n",
    "    \n",
    "for cols, prefix in zip(league_columns[pp_limit_index:],\n",
    "                        prefixes[pp_limit_index:]):\n",
    "    pg_cols = columns_by_postfix(cols, 'pg')\n",
    "    df['l_'+prefix+'_sma_pg_avg'] = df[pg_cols].sum(axis=1) / len(pg_cols)\n",
    "\n",
    "for cols in league_columns:\n",
    "    df.drop(columns=cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Feature engineering (part 2)\n",
    "avgs = columns_by_postfix(df.columns, 'avg')\n",
    "\n",
    "# Transform averaged numerical statistics to paired neighbor difference\n",
    "for col in avgs:\n",
    "    df['diff_'+col] = np.diff(df[col],\n",
    "                              prepend=df.loc[len(df)-1, col])\n",
    "\n",
    "df.drop(columns=avgs, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = columns_by_postfix(df.columns, 'diff_')\n",
    "\n",
    "prefs = prefixes[:-5]\n",
    "prefs.sort()\n",
    "\n",
    "# Exclude columns with only pp or pg suffix\n",
    "to_exclude = [10, 11, 28, 29, 38, 39, 40, 59, 60, 61]\n",
    "pairs = [diffs[i] for i in range(len(diffs))\n",
    "         if i not in to_exclude]\n",
    "\n",
    "leagues = columns_by_postfix(pairs, '_l_')\n",
    "non_leagues = [col for col in pairs\n",
    "               if col not in leagues]\n",
    "\n",
    "for i in range(0, len(non_leagues), 2):\n",
    "    pref = prefs[i // 2]\n",
    "    df[f'labs_{pref}'] = np.abs(df[leagues[i]] - df[leagues[i+1]])\n",
    "    df[f'abs_{pref}'] = np.abs(df[non_leagues[i]] - df[non_leagues[i+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(non_leagues), 2):\n",
    "    pref = prefs[i // 2]\n",
    "    df[f'avg_sum_{pref}'] = (df[non_leagues[i]] + df[non_leagues[i+1]]) / 2\n",
    "    df[f'lavg_sum_{pref}'] = (df[leagues[i]] + df[leagues[i+1]]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = list(itemgetter(*to_exclude)(diffs))\n",
    "\n",
    "# Average statistics for features without pair\n",
    "# Ex.: new_feature = (league_feature + feature) / 2\n",
    "\n",
    "df['e_avgsum_fp0'] = (df[ex[0]] + df[ex[2]]) / 2\n",
    "df['e_avgsum_gamecount'] = (df[ex[1]] + df[ex[3]]) / 2\n",
    "df['e_avgsum_numouts'] = (df[ex[4]] + df[ex[7]]) / 2\n",
    "df['e_avgsum_numpitches'] = (df[ex[5]] + df[ex[8]]) / 2\n",
    "df['e_avgsum_quality'] = (df[ex[6]] + df[ex[9]]) / 2\n",
    "\n",
    "df.drop(columns=diffs, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pps = columns_by_postfix(fp0_cols, 'pp')\n",
    "pgs = [col for col in fp0_cols if col not in pps]\n",
    "pps.sort(key=len)\n",
    "pgs.sort(key=len)\n",
    "\n",
    "# len(pps) == len(pgs) !\n",
    "for i in range(0, len(pps), 2):\n",
    "    df[f'{i}_fp0_pp'] = (df[pps[i]] + df[pps[i+1]]) / 2\n",
    "    df[f'{i}_fp0_pg'] = (df[pgs[i]] + df[pgs[i+1]]) / 2\n",
    "\n",
    "df.drop(columns=fp0_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pps = columns_by_postfix(league_fp0_cols, 'pp')\n",
    "pgs = [col for col in league_fp0_cols if col not in pps]\n",
    "pps.sort(key=len)\n",
    "pgs.sort(key=len)\n",
    "\n",
    "# len(pps) == len(pgs) !\n",
    "for i in range(0, len(pps)-1, 2):\n",
    "    df[f'l_{i}_fp0_pp'] = (df[pps[i]] + df[pps[i+1]]) / 2\n",
    "    df[f'l_{i}_fp0_pg'] = (df[pgs[i]] + df[pgs[i+1]]) / 2\n",
    "\n",
    "df.drop(columns=league_fp0_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['player_id', 'year', 'day', 'month', 'game_id',\n",
    "                 'winddir', 'status_pp', 'status_pg', 'height',\n",
    "                 'p_hand', 'weight', 'precip', 'windspeed',\n",
    "                 'gamescount_in_team', 'gamescount_with_oppteam_in_series'],\n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = columns_by_postfix(df.columns, 'fp0_')\n",
    "\n",
    "for i in range(0, len(fps), 2):\n",
    "    df[f'{i}_fp0_'] = (df[fps[i]] + df[fps[i+1]]) / 2\n",
    "    \n",
    "df.drop(columns=fps, inplace=True)\n",
    "\n",
    "print(f'Data finishing shape {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reordered_cols = df.columns.drop('fp0').insert(0, 'fp0')\n",
    "df = df.reindex(columns=reordered_cols)\n",
    "\n",
    "X = df[df.columns[1:]]\n",
    "Y = df[df.columns[0]]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Train-validation split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    X_train, Y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def adjusted_r2(x: pd.DataFrame, r2):\n",
    "    nominator = (1 - r2) * (len(x) - 1)\n",
    "    denominator = len(x) - len(x.columns) - 1\n",
    "    return 1 - nominator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import xgboost\n",
    "\n",
    "k_fold = KFold(n_splits=6, shuffle=True, random_state=0)\n",
    "\n",
    "xgb_regr = xgboost.XGBRegressor(random_state=1)\n",
    "xgb_regr = xgb_regr.fit(X_train, Y_train)\n",
    "\n",
    "Y_train_pred = xgb_regr.predict(X_train)\n",
    "mse_train = mean_squared_error(Y_train, Y_train_pred)\n",
    "rmse_train = np.sqrt(mse_train)\n",
    "r2_train = r2_score(Y_train, Y_train_pred)\n",
    "r2_adj_train = adjusted_r2(X_train, r2_train)\n",
    "print(f'Train rmse: {rmse_train:.4f}')\n",
    "print(f'Train adj. R2: {r2_adj_train:.4f}')\n",
    "\n",
    "Y_pred = xgb_regr.predict(X_test)\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "r2_adj = adjusted_r2(X_test, r2)\n",
    "print(f'Test rmse: {rmse:.4f}')\n",
    "print(f'Test adj. R2: {r2_adj:.4f}')\n",
    "\n",
    "cv_score = cross_val_score(xgb_regr, X_val, Y_val, cv=k_fold)\n",
    "print(f'Cross validation mean: {cv_score.mean():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "result = permutation_importance(xgb_regr, X_train, Y_train, random_state=1)\n",
    "perm_sorted_idx = result.importances_mean.argsort()\n",
    "\n",
    "tree_importance_sorted_idx = np.argsort(xgb_regr.feature_importances_)\n",
    "tree_indices = np.arange(0, len(xgb_regr.feature_importances_)) + 0.5\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 35))\n",
    "ax.barh(tree_indices,\n",
    "        xgb_regr.feature_importances_[tree_importance_sorted_idx], height=0.7)\n",
    "ax.set_yticklabels(X.columns[tree_importance_sorted_idx])\n",
    "ax.set_yticks(tree_indices)\n",
    "ax.set_ylim((0, len(xgb_regr.feature_importances_)))\n",
    "fig.tight_layout()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 35))\n",
    "ax.boxplot(result.importances[perm_sorted_idx].T, vert=False,\n",
    "            labels=X.columns[perm_sorted_idx])\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}